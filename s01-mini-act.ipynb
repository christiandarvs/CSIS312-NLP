{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lang.en import English\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score\n",
    "\n",
    "# Download NLTK\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "# tokenizer model used for splitting text into sentences to words\n",
    "\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "def preprocess(user_text):\n",
    "    text_token = word_tokenize(user_text)\n",
    "    stopwords_en = stopwords.words(\"english\")\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    lemmatized_words = [\n",
    "        lemmatizer.lemmatize(word.lower())\n",
    "        for word in text_token\n",
    "        if word.lower() not in stopwords_en\n",
    "    ]\n",
    "\n",
    "    clean_words = [stemmer.stem(word) for word in lemmatized_words]\n",
    "\n",
    "    return \" \".join(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"The movie was fantastic, I loved every moment of it\",\n",
    "    \"The food was terrible, I would never eat there again\",\n",
    "    \"I had a great time at the concert\",\n",
    "    \"The service at the restaurant was horrible\",\n",
    "    \"I realty enjoyed the book\",\n",
    "    \"The hotel room was dirty and uncomfortable\",\n",
    "    \"I am very satisfied with my purchase\",\n",
    "    \"The delivery was late and the package was damaged\",\n",
    "    \"The customer support was very helpful\",\n",
    "    \"I am disappointed with the quality of the product\",\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    \"Positive\",\n",
    "    \"Negative\",\n",
    "    \"Positive\",\n",
    "    \"Negative\",\n",
    "    \"Positive\",\n",
    "    \"Negative\",\n",
    "    \"Positive\",\n",
    "    \"Negative\",\n",
    "    \"Positive\",\n",
    "    \"Negative\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_texts = [\n",
    "    \"The vacation was amazing, I wish I could relive it\",\n",
    "    \"The coffee was bitter, I would not order it again\",\n",
    "    \"The staff at the hotel were rude and unprofessional\",\n",
    "    \"The shoes were uncomfortable, and I regret buying them\",\n",
    "    \"I had a wonderful time visiting the museum, it was fascinating\",\n",
    "    \"The product arrived damaged, and the return process was frustrating\",\n",
    "    \"The waiter was polite and made the dining experience enjoyable\",\n",
    "]\n",
    "\n",
    "labels_new_texts = [\n",
    "    \"Positive\",\n",
    "    \"Negative\",\n",
    "    \"Negative\",\n",
    "    \"Negative\",\n",
    "    \"Positive\",\n",
    "    \"Negative\",\n",
    "    \"Positive\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ``CountVectorizer()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Negative']\n",
      "Train Accuracy Score: 1.0%\n",
      "Train F1 Score: 1.0%\n",
      "Train Recall Score: 1.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "model.fit(texts, labels)\n",
    "\n",
    "predictions = [model.predict([text])[0] for text in texts]\n",
    "print(predictions)\n",
    "print(f\"Train Accuracy Score: {accuracy_score(labels, predictions)}%\")\n",
    "print(f\"Train F1 Score: {f1_score(labels, predictions, pos_label='Positive')}%\")\n",
    "print(\n",
    "    f\"Train Recall Score: {recall_score(labels, predictions, pos_label='Positive')}%\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vacation was amazing, I wish I could relive it: \t\t ---> Negative\n",
      "The coffee was bitter, I would not order it again: \t\t ---> Negative\n",
      "The staff at the hotel were rude and unprofessional: \t\t ---> Negative\n",
      "The shoes were uncomfortable, and I regret buying them: \t\t ---> Negative\n",
      "I had a wonderful time visiting the museum, it was fascinating: \t\t ---> Positive\n",
      "The product arrived damaged, and the return process was frustrating: \t\t ---> Negative\n",
      "The waiter was polite and made the dining experience enjoyable: \t\t ---> Negative\n",
      "\n",
      "Test Accuracy Score: 0.714%\n",
      "Test F1 Score: 0.5%\n",
      "Test Recall Score: 0.333%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_new = [model.predict([new_text])[0] for new_text in new_texts]\n",
    "\n",
    "for i, prediction in enumerate(predictions_new):\n",
    "    print(f\"{new_texts[i]}: \\t\\t ---> {prediction}\")\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"\\nTest Accuracy Score: {accuracy_score(labels_new_texts, predictions_new):.3f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"Test F1 Score: {f1_score(labels_new_texts, predictions_new, pos_label='Positive')}%\"\n",
    ")\n",
    "print(\n",
    "    f\"Test Recall Score: {recall_score(labels_new_texts, predictions_new, pos_label='Positive'):.3f}%\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ``TfidfVectorizer()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Negative', 'Positive', 'Negative']\n",
      "Train Accuracy Score: 1.0%\n",
      "Train F1 Score: 1.0%\n",
      "Train Recall Score: 1.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "preprocessed_texts = [preprocess(text) for text in texts]\n",
    "\n",
    "model2 = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "model2.fit(preprocessed_texts, labels)\n",
    "\n",
    "predictions = [\n",
    "    model2.predict([preprocessed_text])[0] for preprocessed_text in preprocessed_texts\n",
    "]\n",
    "print(predictions)\n",
    "print(f\"Train Accuracy Score: {accuracy_score(labels, predictions)}%\")\n",
    "print(f\"Train F1 Score: {f1_score(labels, predictions, pos_label='Positive')}%\")\n",
    "print(\n",
    "    f\"Train Recall Score: {recall_score(labels, predictions, pos_label='Positive')}%\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vacat amaz , wish could reliv: \t\t ---> Negative\n",
      "coffe bitter , would order: \t\t ---> Negative\n",
      "staff hotel rude unprofession: \t\t ---> Negative\n",
      "shoe uncomfort , regret buy: \t\t ---> Negative\n",
      "wonder time visit museum , fascin: \t\t ---> Positive\n",
      "product arriv damag , return process frustrat: \t\t ---> Negative\n",
      "waiter polit made dine experi enjoy: \t\t ---> Positive\n",
      "\n",
      "Test Accuracy Score: 0.857%\n",
      "Test F1 Score: 0.8%\n",
      "Test Recall Score: 0.667%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessed_new_texts = [preprocess(new_text) for new_text in new_texts]\n",
    "\n",
    "predictions = model2.predict(preprocessed_new_texts)\n",
    "\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print(f\"{preprocessed_new_texts[i]}: \\t\\t ---> {prediction}\")\n",
    "\n",
    "print(f\"\\nTest Accuracy Score: {accuracy_score(labels_new_texts, predictions):.3f}%\")\n",
    "print(\n",
    "    f\"Test F1 Score: {f1_score(labels_new_texts, predictions, pos_label='Positive')}%\"\n",
    ")\n",
    "print(\n",
    "    f\"Test Recall Score: {recall_score(labels_new_texts, predictions, pos_label='Positive'):.3f}%\\n\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
