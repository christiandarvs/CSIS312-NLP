{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summative Exam\n",
    "\n",
    "*Submitted by:*  \n",
    "**Christian Elijah Darvin**  \n",
    "BCS32  \n",
    "College of Information and Computer Studies - De La Salle University DasmariÃ±as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(user_text):\n",
    "    \"\"\"\n",
    "    Preprocess the input text: tokenize and remove punctuation.\n",
    "    \"\"\"\n",
    "    sentences = re.split(r\"[.!?\\n]\", user_text)\n",
    "    cleaned_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence.strip():\n",
    "            text_token = word_tokenize(sentence.lower())\n",
    "            clean_words = [word for word in text_token if word not in punctuation]\n",
    "            cleaned_sentences.append(clean_words)\n",
    "\n",
    "    return cleaned_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def ngram_model(sentences, n):\n",
    "    \"\"\"\n",
    "    Generate n-grams and count their frequencies.\n",
    "    \"\"\"\n",
    "    ngram_count = defaultdict(int)\n",
    "    for sentence in sentences:\n",
    "        if len(sentence) >= n:\n",
    "            for i in range(len(sentence) - n + 1):\n",
    "                n_gram = tuple(sentence[i : i + n])\n",
    "                ngram_count[n_gram] += 1\n",
    "\n",
    "    return ngram_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(text, n, min_count):\n",
    "    \"\"\"\n",
    "    Generate n-grams, count their frequencies, and filter by minimum frequency.\n",
    "    \"\"\"\n",
    "    tokens = preprocess(text)\n",
    "    ngram_counts = ngram_model(tokens, n)\n",
    "    filtered_ngrams = {k: v for k, v in ngram_counts.items() if v >= min_count}\n",
    "    sorted_ngrams = sorted(filtered_ngrams.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    ngrams_list = [\" \".join(k) for k, _ in sorted_ngrams]\n",
    "    frequency_dict = {\" \".join(k): v for k, v in sorted_ngrams}\n",
    "\n",
    "    return {\n",
    "        \"ngrams\": ngrams_list,\n",
    "        \"frequency\": frequency_dict,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: The brown fox jumps over the lazy dog.\n",
      "\n",
      "Output:\n",
      "N-grams: ['the brown', 'brown fox', 'fox jumps', 'jumps over', 'over the', 'the lazy', 'lazy dog']\n",
      "\n",
      "Frequency: {'the brown': 1, 'brown fox': 1, 'fox jumps': 1, 'jumps over': 1, 'over the': 1, 'the lazy': 1, 'lazy dog': 1}\n"
     ]
    }
   ],
   "source": [
    "user_text = input(\"Enter a text for analysis: \")\n",
    "n = int(input(\"Enter the size of the n-grams (e.g., 2 for bigrams): \"))\n",
    "min_count = int(input(\"Enter the minimum frequency threshold: \"))\n",
    "\n",
    "if not user_text.strip():\n",
    "    print(\"Error: Input text is empty.\")\n",
    "elif n <= 0:\n",
    "    print(\"Error: N-gram size must be greater than 0.\")\n",
    "else:\n",
    "    print(f\"Input: {user_text}\")\n",
    "    result = generate_ngrams(user_text, n, min_count)\n",
    "    print(\"\\nOutput:\")\n",
    "    print(\"N-grams:\", result[\"ngrams\"])\n",
    "    print(\"\\nFrequency:\", result[\"frequency\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
